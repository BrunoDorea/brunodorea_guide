{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bruno D\u00f3rea Projeto de documenta\u00e7\u00e3o dos meus projetos. readme.md name: 'Bruno D\u00f3rea', located_in: 'Bahia, Brazil', job: ['Developer', 'QA'], education: [\"University Est\u00e1cio de S\u00e1\"], company: [\"Spread\"] Linguagens Ferramentas","title":"Home"},{"location":"#bruno-dorea","text":"Projeto de documenta\u00e7\u00e3o dos meus projetos.","title":"Bruno D\u00f3rea"},{"location":"#readmemd","text":"name: 'Bruno D\u00f3rea', located_in: 'Bahia, Brazil', job: ['Developer', 'QA'], education: [\"University Est\u00e1cio de S\u00e1\"], company: [\"Spread\"]","title":"readme.md"},{"location":"about/","text":"Sobre o MkDocs Comandos B\u00e1sicos mkdocs new [dir-name] - Criar um novo projeto. mkdocs serve - Iniciar o servidor de live-reloading. mkdocs build - Compilar o site da documenta\u00e7\u00e3o. mkdocs -h - Ajuda e outras dicas. Layout da Documenta\u00e7\u00e3o - mkdocs.yml # Arquivo de configura\u00e7\u00e3o. - docs/ index.md # P\u00e1gina inicial da documenta\u00e7\u00e3o. about.md # P\u00e1gina sobre - docs/nav chatbot.md # P\u00e1gina do projeto Suporte ao Cliente atrav\u00e9s de um Chatbot de IA Desenvolvimento Est\u00e1 documenta\u00e7\u00e3o foi desenvolvida por Bruno D\u00f3rea, com ajuda da biblioteca MkDocs . O tema utilizado \u00e9 o Dracula .","title":"Sobre"},{"location":"about/#sobre-o-mkdocs","text":"","title":"Sobre o MkDocs"},{"location":"about/#comandos-basicos","text":"mkdocs new [dir-name] - Criar um novo projeto. mkdocs serve - Iniciar o servidor de live-reloading. mkdocs build - Compilar o site da documenta\u00e7\u00e3o. mkdocs -h - Ajuda e outras dicas.","title":"Comandos B\u00e1sicos"},{"location":"about/#layout-da-documentacao","text":"- mkdocs.yml # Arquivo de configura\u00e7\u00e3o. - docs/ index.md # P\u00e1gina inicial da documenta\u00e7\u00e3o. about.md # P\u00e1gina sobre - docs/nav chatbot.md # P\u00e1gina do projeto Suporte ao Cliente atrav\u00e9s de um Chatbot de IA","title":"Layout da Documenta\u00e7\u00e3o"},{"location":"about/#desenvolvimento","text":"Est\u00e1 documenta\u00e7\u00e3o foi desenvolvida por Bruno D\u00f3rea, com ajuda da biblioteca MkDocs . O tema utilizado \u00e9 o Dracula .","title":"Desenvolvimento"},{"location":"nav/chatbot/","text":"Suporte ao Cliente atrav\u00e9s de um Chatbot de IA Implementar um chatbot de IA para fornecer suporte ao cliente automatizado. O chatbot pode ser treinado para compreender e responder a uma variedade de perguntas frequentes, solucionar problemas comuns e direcionar consultas mais complexas para atendentes humanos. Isso permitir\u00e1 que os clientes recebam respostas instant\u00e2neas para suas d\u00favidas e problemas, reduzindo os tempos de espera e melhorando a experi\u00eancia do cliente. Repositorio do Github Pr\u00e9-requisitos 1 - Baixar o Python . 2 - Baixar o VS Code . 3 - Instalar o ambiente virtual: python -m venv chatbot chatbot\\Scripts\\activate 4 - Instalar os pacotes necess\u00e1rios do Python: pip install -r requirements.txt 5 - Ter uma conta na openai e gerar a API Key Desenvolvimento Importa\u00e7\u00e3o dos m\u00f3dulos e classes necess\u00e1rios from langchain.callbacks.base import BaseCallbackHandler from langchain.chat_models import ChatOpenAI from langchain.schema import ChatMessage import streamlit as st Define uma classe de callback personalizada que estende a classe BaseCallbackHandler class StreamHandler(BaseCallbackHandler): def __init__(self, container, initial_text=\"\"): self.container = container self.text = initial_text # Este m\u00e9todo \u00e9 chamado sempre que um novo token \u00e9 gerado pelo modelo de linguagem def on_llm_new_token(self, token: str, **kwargs) -> None: self.text += token self.container.markdown(self.text) Cria uma barra lateral na aplica\u00e7\u00e3o Streamlit para inserir a chave da API da OpenAI with st.sidebar: openai_api_key = st.text_input(\"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\", type=\"password\") Se a chave \"messages\" n\u00e3o estiver presente no estado da sess\u00e3o, inicializa com uma mensagem padr\u00e3o do assistente if \"messages\" not in st.session_state: st.session_state[\"messages\"] = [ChatMessage(role=\"assistant\", content=\"Fala, beleza? Como posso ajudar?\")] Exibe as mensagens do chat armazenadas no estado da sess\u00e3o for msg in st.session_state.messages: st.chat_message(msg.role).write(msg.content) Verifica se o usu\u00e1rio inseriu uma nova mensagem if prompt := st.chat_input(): # Adiciona a mensagem do usu\u00e1rio ao estado da sess\u00e3o st.session_state.messages.append(ChatMessage(role=\"user\", content=prompt)) st.chat_message(\"user\").write(prompt) # Se a chave da API da OpenAI n\u00e3o foi fornecida, exibe uma mensagem informativa e interrompe if not openai_api_key: st.info(\"Por favor, adicione sua chave da API da OpenAI para continuar.\") st.stop() # Gera uma resposta usando o modelo de linguagem e exibe como mensagem do assistente with st.chat_message(\"assistant\"): # Cria uma inst\u00e2ncia de StreamHandler para lidar com atualiza\u00e7\u00f5es em tempo real da resposta do assistente stream_handler = StreamHandler(st.empty()) # Inicializa o modelo ChatOpenAI com a chave da API fornecida e o modo de streaming llm = ChatOpenAI(openai_api_key=openai_api_key, streaming=True, callbacks=[stream_handler]) # Gera uma resposta usando o modelo de linguagem e adiciona ao estado da sess\u00e3o response = llm(st.session_state.messages) st.session_state.messages.append(ChatMessage(role=\"assistant\", content=response.content)) Executando o StreamLit No terminal digitar o comando streamlit run app.py e aguardar um pouco e o navegador ir\u00e1 abrir na p\u00e1gina http://localhost:8501 para testar a aplica\u00e7\u00e3o.","title":"Chatbot"},{"location":"nav/chatbot/#suporte-ao-cliente-atraves-de-um-chatbot-de-ia","text":"Implementar um chatbot de IA para fornecer suporte ao cliente automatizado. O chatbot pode ser treinado para compreender e responder a uma variedade de perguntas frequentes, solucionar problemas comuns e direcionar consultas mais complexas para atendentes humanos. Isso permitir\u00e1 que os clientes recebam respostas instant\u00e2neas para suas d\u00favidas e problemas, reduzindo os tempos de espera e melhorando a experi\u00eancia do cliente. Repositorio do Github","title":"Suporte ao Cliente atrav\u00e9s de um Chatbot de IA"},{"location":"nav/chatbot/#pre-requisitos","text":"1 - Baixar o Python . 2 - Baixar o VS Code . 3 - Instalar o ambiente virtual: python -m venv chatbot chatbot\\Scripts\\activate 4 - Instalar os pacotes necess\u00e1rios do Python: pip install -r requirements.txt 5 - Ter uma conta na openai e gerar a API Key","title":"Pr\u00e9-requisitos"},{"location":"nav/chatbot/#desenvolvimento","text":"Importa\u00e7\u00e3o dos m\u00f3dulos e classes necess\u00e1rios from langchain.callbacks.base import BaseCallbackHandler from langchain.chat_models import ChatOpenAI from langchain.schema import ChatMessage import streamlit as st Define uma classe de callback personalizada que estende a classe BaseCallbackHandler class StreamHandler(BaseCallbackHandler): def __init__(self, container, initial_text=\"\"): self.container = container self.text = initial_text # Este m\u00e9todo \u00e9 chamado sempre que um novo token \u00e9 gerado pelo modelo de linguagem def on_llm_new_token(self, token: str, **kwargs) -> None: self.text += token self.container.markdown(self.text) Cria uma barra lateral na aplica\u00e7\u00e3o Streamlit para inserir a chave da API da OpenAI with st.sidebar: openai_api_key = st.text_input(\"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\", type=\"password\") Se a chave \"messages\" n\u00e3o estiver presente no estado da sess\u00e3o, inicializa com uma mensagem padr\u00e3o do assistente if \"messages\" not in st.session_state: st.session_state[\"messages\"] = [ChatMessage(role=\"assistant\", content=\"Fala, beleza? Como posso ajudar?\")] Exibe as mensagens do chat armazenadas no estado da sess\u00e3o for msg in st.session_state.messages: st.chat_message(msg.role).write(msg.content) Verifica se o usu\u00e1rio inseriu uma nova mensagem if prompt := st.chat_input(): # Adiciona a mensagem do usu\u00e1rio ao estado da sess\u00e3o st.session_state.messages.append(ChatMessage(role=\"user\", content=prompt)) st.chat_message(\"user\").write(prompt) # Se a chave da API da OpenAI n\u00e3o foi fornecida, exibe uma mensagem informativa e interrompe if not openai_api_key: st.info(\"Por favor, adicione sua chave da API da OpenAI para continuar.\") st.stop() # Gera uma resposta usando o modelo de linguagem e exibe como mensagem do assistente with st.chat_message(\"assistant\"): # Cria uma inst\u00e2ncia de StreamHandler para lidar com atualiza\u00e7\u00f5es em tempo real da resposta do assistente stream_handler = StreamHandler(st.empty()) # Inicializa o modelo ChatOpenAI com a chave da API fornecida e o modo de streaming llm = ChatOpenAI(openai_api_key=openai_api_key, streaming=True, callbacks=[stream_handler]) # Gera uma resposta usando o modelo de linguagem e adiciona ao estado da sess\u00e3o response = llm(st.session_state.messages) st.session_state.messages.append(ChatMessage(role=\"assistant\", content=response.content))","title":"Desenvolvimento"},{"location":"nav/chatbot/#executando-o-streamlit","text":"No terminal digitar o comando streamlit run app.py e aguardar um pouco e o navegador ir\u00e1 abrir na p\u00e1gina http://localhost:8501 para testar a aplica\u00e7\u00e3o.","title":"Executando o StreamLit"}]}